MaverickChess and ShallowBlue
by Commander Spock and Mister Finney

###############################################################################
Introduction (Matt and James)
###############################################################################
We decided purposely to tackle the challenging task of creating a meaningful
chess AI. Knowing that this problem is notoriously complex, and that far
greater computer scientists have spent careers on this, we fully expected to
come up with an interesting exploration that did not yield a competitive AI.
However, whether by chance or persistence, we were able to develop a system
that makes seemingly logical moves in a reasonable amount of time (5 minutes).
While it would not beat an industrial-stregnth chess AI, it was an incredible
learning experience and developed in each of us an appreciation for the great
challenges in algorithms, artificial intelligence, and high performance
computing.


###############################################################################
Related Work (Matt and James)
###############################################################################



###############################################################################
Approach (Matt and James)
###############################################################################

Our project is essentially the combination of two systems:
 - MaverickChess, a self-created platform for chess AIs to be pitted against
   each other in an open arena either locally or across the internet. It
   includes a REPL client to allow a human to play another human or AI, server
   master that holds state and communicates with clients, client code to
   enable rapid development of AIs and other players, 

   ADDED BENEFIT: this could be re-used for future courses.

 - ShallowBlue, a proficient mid-game AI based on quiescence-search, heuristic
   board evaluation, alpha-beta pruning, move enumeration, and other analytics.
   It intentionally does not include an opening database or end-game tablebases,
   as these are mechanical components and not interesting AI components. With
   these, however, the AI would perform substantially better.

Each of these systems were a large undertaking, and together they form the
chess system we developed for this course.

There were a few side-tasks that required work as well:
 - Writing the various reports
 - Scripts that provided data to help choose the heuristic weight constants
   in ShallowBlue
 - Platform for 'genetic' evolution of constant weights (didn't make it into
   the code)


___ Overall Architecture ___


___ MaverickChess Architecture ___


___ ShallowBlue Architecture ___


___ Primary Heuristics Considered ___


___ Search and Move Choice ___

Our AI constructs a tree of possible board moves, and conducts a breadth-first minimax search using alpha-beta pruning.  At each level, the possible moves are enumerated.  For each one, a recursive call is made to the search function, which terminates once the maximum depth is reached.  At the terminal depth, a quiescent search function is called that performs a limited additional search only considering captures.  This helps combat the horizon affect by making it less likely that search is terminated one move prior to a very unfavorable capture.

Successive evaluations at the same level in our AI's minimax search can be pruned depending on the results of their predecessors.  For example, say that a node of depth 2 is being considered. If a possible friendly move (a child node of this level-2 node) is evaluated at level 3, and it is found we could achieve a board state that is more desirable than that of another child we've evaluated, we need not explore this new child node because we know the enemy will not pick it. To this end, each recursive call to the QLAI class's _boardSearch function includes new values for the maximum and minimum board likability values to be considered by that call.

___ Move Enumeration ___


___ Possible Future Work ___




###############################################################################
Results and Discussion (Brad)
###############################################################################
Analysis

Unfortunately, due to time constraints, only a small sample of test data was able to be recorded. Data was collected for 20 games of our chess AI playing against a popular open source chess program, GNUchess, on normal difficulty. For the trials, our AI was run using varying weights for heuristics the AI used to calculate the best move based on the likability of possible boards. There are five heuristics the AI uses to make decisions: pieceValue (Total value of all a player’s pieces on the board), InCheck (If a player’s King is in check), piecesUnderAttack (Total value of all a player’s pieces that are under attack), emptySpaceCoverage (Value of empty squares a player can attack, importance on  center squares), piecesCovered (Value of a player’s pieces whose positions could be immediately retaken if captured).

To test our AI against the GNUchess AI, games had to played manually by playing a human against two computers simultaneously, and feeding in the AI moves against each other. Of the 20 games that were recorded, the GNUchess AI won all 20. Though those results are discouraging, the benefit of testing with the human mediator is that every move that the AI makes is observable, as opposed to just seeing the end result of the game with automated testing. Through this method, a substantial increase in performance was noticed after observation and tweaking of heuristic weights. Below is the table showing the progression of weights as they were tweaked based on performance. Each set of weights was tested multiple times, the table shows each set of weights.

Sets of Tested Heuristic Weights
Set #   pieceValue       inCheck        piecesUnderAttack       emptySpaceCoverage      piecesCovered
1   8   10               5              3                       2
2   8   10               7              2                       5
3   8   8                7              1                       6
4   7   10               10             2                       8
5   7   10               9              1                       3
6   2   10               7              3                       9
7   1   10               8              2                       2
8   2   10               8              2                       2

The first set of heuristic weights was hand-picked by the members of the project team as a starting point based on guessing what would perform well. After running many games with Set 1, it was observed that though the AI was sufficient in staying out of check, it played too recklessly with other pieces. It would regularly choose to move other pieces into dangerous spaces with many safe moves available. As testing went on and tweaks were made, the AI started putting less pieces into dangerous positions, was giving itself better positioning across the board, and the games went much longer before our AI was put into checkmate. As you can see from the table, the AI started to perform better when the weight of the pieceValue heuristic was lowered and the weight of piecesUnderAttack heuristic was raised. I believe it performed better because the AI was putting more importance on the total number of pieces that were under attack as opposed to specific pieces based on the value of their type. The inCheck weight was left at 10 for the majority of the sets because when it was lowered, all test games ended very quickly with the AI putting more focus on other aspects of the game. Given more time for testing, it is hypothesized that putting more weight in the emptySpaceCovered heuristic would help to increase performance of the AI because if it put more weight in have board coverage, it is assumed to have overall better piece positioning.
One limitation that is expected to have impacted the performance of our AI during testing  is the time restriction on our AI for searching the possible move tree. In order to increase the speed of testing, the a two minute limit was put on the quiescence search. Giving it a time limit meant that the AI would not be able to search as much of the move tree and could be missing better moves that were not found yet.




###############################################################################
References (Matt and James)
###############################################################################
